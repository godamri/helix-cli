package main

import (
	"context"
	"database/sql"
	"fmt"
	"log/slog"
	"os"
	"strings"
	"time" 

	"github.com/go-chi/chi/v5"
	"github.com/go-chi/chi/v5/middleware"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/redis/go-redis/v9"
	"github.com/riandyrn/otelchi"
	"golang.org/x/sync/errgroup"
	"google.golang.org/grpc"
	"google.golang.org/grpc/reflection"

	"go.opentelemetry.io/otel"
	"go.opentelemetry.io/otel/attribute"
	"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
	"go.opentelemetry.io/otel/propagation"
	"go.opentelemetry.io/otel/sdk/resource"
	sdktrace "go.opentelemetry.io/otel/sdk/trace"

	// PGX Stdlib is required to bridge the PGX Pool to *sql.DB for Ent/Legacy support
	"github.com/jackc/pgx/v5/stdlib"

	"github.com/godamri/helix-fnd/app"
	"github.com/godamri/helix-fnd/audit"
	"github.com/godamri/helix-fnd/cache"
	"github.com/godamri/helix-fnd/crypto"
	"github.com/godamri/helix-fnd/database"
	"github.com/godamri/helix-fnd/messaging"
	"github.com/godamri/helix-fnd/server"
	"github.com/godamri/helix-fnd/server/health"
	fndMiddleware "github.com/godamri/helix-fnd/server/middleware"

	pb "{{ .GoModuleName }}/api/proto/v1"

	{{- if eq .Driver "ent" }}
	"{{ .GoModuleName }}/ent"
	"entgo.io/ent/dialect"
	entsql "entgo.io/ent/dialect/sql"
	{{- end }}

	handlerV1 "{{ .GoModuleName }}/internal/adapter/handler/v1"
	"{{ .GoModuleName }}/internal/adapter/repository"
	"{{ .GoModuleName }}/internal/adapter/worker"
	"{{ .GoModuleName }}/internal/core/service"
	localConfig "{{ .GoModuleName }}/internal/pkg/config"
	customMiddleware "{{ .GoModuleName }}/internal/pkg/middleware"
	"{{ .GoModuleName }}/internal/pkg/telemetry"

	_ "{{ .GoModuleName }}/docs"
	httpSwagger "github.com/swaggo/http-swagger"
)

type DebugLogProducer struct {
	logger *slog.Logger
}

func (p *DebugLogProducer) Publish(ctx context.Context, topic string, key string, payload []byte) error {
	p.logger.Info("stub_producer: publishing event (dry-run)", "topic", topic, "key", key, "size", len(payload))
	return nil
}

// @title           {{ .ProjectName }} API
// @version         1.1
// @description     Enterprise Microservice API - {{ if eq .Driver "ent" }}Ent ORM{{ else }}Raw SQL{{ end }} Edition.
func main() {
	// 1. Bootstrap Logger (Basic)
	logger := setupLogger("info", "json")
	slog.SetDefault(logger)

	// 2. Load Config
	if err := localConfig.Load(); err != nil {
		logger.Error("Failed to load config", "error", err)
		os.Exit(1)
	}
	cfg := localConfig.Get()

	// 3. Re-init Logger with Config & OTel Middleware
	logger = setupLogger(cfg.LogLevel, cfg.LogFormat)
	slog.SetDefault(logger)

	// 4. Init Tracing (MUST be before app run for OTelHandler to find Spans)
	tp, err := initTracer(
		context.Background(), 
		cfg.ServiceName, 
		cfg.Environment, 
		cfg.OTelExporterEndpoint, 
		cfg.OTelExporterInsecure,
	)
	
	if err != nil {
		logger.Error("failed to init tracer", "error", err)
	} else {
		logger.Info("OpenTelemetry Tracer initialized", "endpoint", cfg.OTelExporterEndpoint, "insecure", cfg.OTelExporterInsecure)
		
		defer func() {
			if err := tp.Shutdown(context.Background()); err != nil {
				logger.Error("failed to shutdown tracer", "error", err)
			}
		}()
	}

	runner := app.NewRunner(logger)
	runner.Run(func(ctx context.Context) error {
		return run(ctx, logger)
	})
}

func setupLogger(levelStr, format string) *slog.Logger {
	var level slog.Level
	switch strings.ToLower(levelStr) {
	case "debug":
		level = slog.LevelDebug
	case "warn":
		level = slog.LevelWarn
	case "error":
		level = slog.LevelError
	default:
		level = slog.LevelInfo
	}

	opts := &slog.HandlerOptions{
		Level: level,
	}

	var baseHandler slog.Handler
	if strings.ToLower(format) == "text" {
		baseHandler = slog.NewTextHandler(os.Stdout, opts)
	} else {
		baseHandler = slog.NewJSONHandler(os.Stdout, opts)
	}

	// WRAP WITH OTel HANDLER
	otelHandler := telemetry.NewOTelHandler(baseHandler)
	
	return slog.New(otelHandler)
}

func run(ctx context.Context, logger *slog.Logger) error {
	cfg := localConfig.Get()

	logger.Info("Starting {{ .ProjectName }}", "env", cfg.Environment, "infra", "immutable", "driver", "{{ .Driver }}", "strict_mode", cfg.StrictMode)

	// -------------------------------------------------------------------------
	// AUDIT LOGGER SETUP (Async / Kafka)
	// -------------------------------------------------------------------------
	var auditLogger audit.Logger
	var err error

	if len(cfg.KafkaBrokers) > 0 && cfg.Audit.Output == "kafka" {
		logger.Info("Initializing Audit Logger (Kafka Async)...")
		auditLogger, err = audit.NewKafkaLogger(cfg.KafkaBrokers, cfg.Audit.Topic)
		if err != nil {
			return fmt.Errorf("failed to init audit kafka logger: %w", err)
		}
		if closer, ok := auditLogger.(interface{ Close() error }); ok {
			defer closer.Close()
		}
	} else {
		logger.Info("Initializing Audit Logger (Console Async)...")
		
		// Setup Audit Logger compliant with helix-fnd v1.0.4 signature
		al := audit.NewAsyncLogger(os.Stdout, cfg.Audit.BufferSize, cfg.Audit.BlockOnFull, logger)
		
		defer al.Close()
		auditLogger = al
	}

	// -------------------------------------------------------------------------
	// DATABASE INIT (PGX Pool -> SQL Bridge)
	// -------------------------------------------------------------------------
	
	mainPool, err := database.NewPostgres(ctx, database.Config{
		DBDSN:      cfg.DBDSN, 
		DBMaxConns: int32(cfg.DBMaxOpenConns), 
		DBMinConns: int32(cfg.DBMaxIdleConns),
	})
	if err != nil {
		return fmt.Errorf("main db pool init failed: %w", err)
	}
	
	stdMainDB := stdlib.OpenDBFromPool(mainPool)
	defer stdMainDB.Close()

	// WORKER DB CONNECTION (Bulkhead Pattern)
	var stdWorkerDB *sql.DB
	if cfg.WorkerDBDSN != "" && cfg.WorkerDBDSN != cfg.DBDSN {
		logger.Info("Connecting to Worker Database (Isolated Pool)...")
		workerPool, err := database.NewPostgres(ctx, database.Config{
			DBDSN:         cfg.WorkerDBDSN, 
			DBMaxConns:    int32(cfg.WorkerDBMaxOpenConns), 
			DBMinConns:    int32(cfg.WorkerDBMaxIdleConns),
			DBMaxConnLife: cfg.WorkerDBConnMaxLifetime,
		})
		if err != nil {
			return fmt.Errorf("worker db init failed: %w", err)
		}
		stdWorkerDB = stdlib.OpenDBFromPool(workerPool)
		defer stdWorkerDB.Close()
	} else {
		stdWorkerDB = stdMainDB
	}

	{{- if eq .Driver "ent" }}
	// ENT CLIENT INIT
	drv := entsql.OpenDB(dialect.Postgres, stdMainDB)
	entClient := ent.NewClient(ent.Driver(drv))
	{{- end }}

	// Redis
	var rdb *redis.Client
	if cfg.RedisAddr != "" {
		rdb, err = cache.NewRedis(ctx, cache.Config{Addr: cfg.RedisAddr, Password: cfg.RedisPassword, DB: cfg.RedisDB})
		if err != nil {
			return fmt.Errorf("redis init failed: %w", err)
		}
		defer rdb.Close()
	}

	// Auth
	var authMiddleware *fndMiddleware.AuthMiddleware
	if cfg.AuthEnabled {
		jwksClient, err := crypto.NewJWKSCachingClient(
			ctx,
			cfg.AuthJWKSURL, 
			cfg.AuthIssuer, 
			cfg.JWKSRefreshInterval, 
			cfg.AuthJWKSMaxStale, 
			logger,
		)
		if err != nil {
			return fmt.Errorf("auth init failed: %w", err)
		}
		strategy := fndMiddleware.NewJWTStrategy(jwksClient, logger)
		authMiddleware = fndMiddleware.NewAuthMiddleware(strategy)
	}

	// Messaging
	var producer worker.EventProducer
	if len(cfg.KafkaBrokers) > 0 {
		kafkaProducer, err := messaging.NewProducer(messaging.Config{Brokers: cfg.KafkaBrokers}, logger)
		if err != nil {
			return fmt.Errorf("kafka init failed: %w", err)
		}
		defer kafkaProducer.Close()
		producer = kafkaProducer
	} else {
		producer = &DebugLogProducer{logger: logger}
	}

	// WIRING
	{{- if eq .Driver "ent" }}
	repo := repository.New{{ .EntityName }}Repository(entClient)
	txManager := repository.NewEntTxManager(entClient)
	{{- end }}
	{{- if eq .Driver "pgx" }}
	repo := repository.New{{ .EntityName }}Repository(stdMainDB)
	txManager := repository.NewSQLTxManager(stdMainDB)
	{{- end }}
	
	outboxRepo := repository.NewOutboxRepository(stdMainDB)
	
	svc := service.New{{ .EntityName }}Service(repo, outboxRepo, txManager)
	
	healthChecker := health.NewChecker(mainPool, logger)

	g, groupCtx := errgroup.WithContext(ctx)

	// --- HTTP/GRPC SERVER ---
	if cfg.AppMode == "all" || cfg.AppMode == "api" {
		var r *chi.Mux
		var grpcSrv *grpc.Server

		if cfg.EnableHTTP {
			httpHandler := handlerV1.New{{ .EntityName }}Handler(svc)
			r = chi.NewRouter()

			// --- 1. OBSERVABILITY (Must be first) ---
			// This middleware creates the Root Span for the request
			r.Use(otelchi.Middleware(cfg.ServiceName, otelchi.WithChiRoutes(r)))

			// --- 2. RESILIENCE & SECURITY BASE (Hardening) ---
			// Trust Proxy Headers (X-Forwarded-For). Critical for Audit Log & Rate Limiting behind LB.
			r.Use(middleware.RealIP)
			// DoS Protection: Limit Request Body to 2MB. Prevents memory exhaustion.
			r.Use(middleware.RequestSize(2 * 1024 * 1024))
			// URL Sanitization
			r.Use(middleware.CleanPath)

			r.Use(fndMiddleware.SecurityHeaders)
			r.Use(fndMiddleware.TraceIDMiddleware)
			r.Use(fndMiddleware.MetricsMiddleware)
			r.Use(fndMiddleware.LoggerMiddleware)
			r.Use(fndMiddleware.PanicRecovery)

			if authMiddleware != nil {
				r.Use(authMiddleware.HTTPMiddleware)
			}
			
			r.Use(customMiddleware.AuditMiddleware(auditLogger))

			if rdb != nil {
				r.Use(fndMiddleware.RateLimitMiddleware(rdb, cfg.RateLimitGlobalRate, cfg.RateLimitGlobalBurst, cfg.RateLimitGlobalPeriod))
				
				// Idempotency: 
				// STRICT Mode (Financial) = FailOpen: false (Reject if Redis down)
				// PERMISSIVE Mode (General) = FailOpen: true (Accept if Redis down)
				r.Use(fndMiddleware.IdempotencyMiddleware(fndMiddleware.IdempotencyConfig{
					HeaderKey: "Idempotency-Key", 
					Expiry: cfg.IdempotencyExpiry, 
					RedisClient: rdb, 
					Logger: logger,
					FailOpen: !cfg.StrictMode,
				}))
			}

			r.Handle("/metrics", promhttp.Handler())
			healthChecker.RegisterRoutes(r)

			if cfg.DocsEnabled {
				r.Get("/swagger/*", httpSwagger.Handler(httpSwagger.URL("/swagger/doc.json")))
			}

			r.Route("/v1", func(r chi.Router) {
				if cfg.DeprecationActive {
					sunsetTime, err := time.Parse("2006-01-02", cfg.DeprecationSunset)
					if err != nil {
						logger.Warn("Invalid deprecation sunset date format, disabling deprecation middleware", "date", cfg.DeprecationSunset, "error", err)
					} else {
						r.Use(customMiddleware.DeprecationMiddleware(customMiddleware.DeprecationConfig{
							Active: true, SunsetDate: sunsetTime, MigrationLink: cfg.DeprecationLink,
						}))
					}
				}
				r.Route("/{{ .EntityNameCamel }}s", func(r chi.Router) {
					r.Post("/", httpHandler.Create)
					r.Get("/{id}", httpHandler.GetByID)
					r.Put("/{id}", httpHandler.Update)
					r.Delete("/{id}", httpHandler.Delete)
					r.Get("/", httpHandler.List)
					r.Post("/bulk", httpHandler.BulkCreate)
					r.Delete("/bulk", httpHandler.BulkDelete)
				})
			})
		}

		if cfg.EnableGRPC {
			grpcHandler := handlerV1.New{{ .EntityName }}GrpcHandler(svc)
			
			unaryInterceptors := []grpc.UnaryServerInterceptor{
				fndMiddleware.GRPCRecoveryInterceptor,
			}

			if authMiddleware != nil {
				unaryInterceptors = append(unaryInterceptors, authMiddleware.GRPCUnaryInterceptor)
			}

			if rdb != nil {
				unaryInterceptors = append(unaryInterceptors, fndMiddleware.GRPCRateLimitInterceptor(
					rdb, 
					cfg.RateLimitGlobalRate, 
					cfg.RateLimitGlobalBurst, 
					cfg.RateLimitGlobalPeriod,
				))
			}
			opts := []grpc.ServerOption{
				grpc.ChainUnaryInterceptor(unaryInterceptors...),
			}

			grpcSrv = grpc.NewServer(opts...)
			pb.Register{{ .EntityName }}ServiceServer(grpcSrv, grpcHandler)
			if cfg.GRPCEnableReflection {
				reflection.Register(grpcSrv)
				logger.Info("gRPC Reflection enabled")
			} else {
				logger.Warn("gRPC Reflection disabled (API Discovery unavailable)")
			}
		}

		srv := server.New(server.Config{
			EnableHTTP: cfg.EnableHTTP,
			EnableGRPC: cfg.EnableGRPC,
			HTTPPort: fmt.Sprintf("%d", cfg.AppPort),
			GRPCPort: fmt.Sprintf("%d", cfg.GRPCPort),
			HTTPReadTimeout: cfg.HTTPReadTimeout,
			HTTPWriteTimeout: cfg.HTTPWriteTimeout,
			ShutdownTimeout: cfg.ShutdownTimeout,
			MTLSEnabled: cfg.MTLSEnabled,
			MTLSCACert: cfg.MTLSCACert,
			MTLSServerCert: cfg.MTLSCACert,
			MTLSServerKey: cfg.MTLSServerKey,
		}, logger, r, grpcSrv)

		g.Go(func() error { return srv.Start(groupCtx) })
	}

	// --- WORKER ---
	if cfg.AppMode == "all" || cfg.AppMode == "worker" {
		consumerMgr := messaging.NewConsumerManager(logger)
		outboxWorker := worker.NewOutboxWorker(stdWorkerDB, producer)

		// ---------------------------------------------------------------------
		// MANUAL CONSUMER WIRING (ENABLED BY DEFAULT)
		// ---------------------------------------------------------------------

		// 1. Initialize Handler
		consumerHandler := worker.New{{ .EntityName }}ConsumerHandler(logger)

		// 2. Initialize Consumer with DLQ Producer (using the SAME producer as Outbox)
		// This creates a circular topology: App -> Outbox -> Kafka -> Consumer -> (Error) -> Kafka (DLQ)
		consumer, err := messaging.NewConsumer(
			messaging.ConsumerConfig{
				Brokers:        cfg.KafkaBrokers,
				GroupID:        cfg.ServiceName + "-group",
				Topic:          "{{ .EntityNameLower }}.created", // Listening to self events for demo
				MaxRetries:     3,                          // 3 Retries before DLQ
				InitialBackoff: 1 * time.Second,
				MaxBackoff:     5 * time.Second,
				DLQTopic:       "{{ .EntityNameLower }}.created.dlq", // Explicit DLQ topic
				StrictMode:     cfg.StrictMode,
			},
			logger,
			consumerHandler.Handle,
			producer, // <--- PASSING THE PRODUCER AS DLQ PRODUCER
		)
		if err != nil {
			logger.Error("Failed to init consumer", "error", err)
			os.Exit(1)
		}

		// 3. Register to Manager
		consumerMgr.Register(consumer)

		g.Go(func() error {
			consumerMgr.Start(groupCtx)
			<-groupCtx.Done()
			return consumerMgr.Close()
		})
		g.Go(func() error {
			outboxWorker.Start(groupCtx)
			return nil
		})
	}

	return g.Wait()
}

func initTracer(
	ctx context.Context, 
	name string, 
	env string, 
	endpoint string, 
	insecure bool,
) (*sdktrace.TracerProvider, error) {
	otel.SetErrorHandler(otel.ErrorHandlerFunc(func(err error) {
		fmt.Fprintf(os.Stderr, "OTEL ERROR: %v\n", err)
	}))

	opts := []otlptracegrpc.Option{
		otlptracegrpc.WithEndpoint(endpoint),
	}
	
	if insecure {
		opts = append(opts, otlptracegrpc.WithInsecure())
	}

	exporter, err := otlptracegrpc.New(ctx, opts...)
	if err != nil {
		return nil, fmt.Errorf("failed to create otlp exporter: %w", err)
	}

    res, err := resource.New(ctx, resource.WithAttributes(
        attribute.String("service.name", name),
        attribute.String("deployment.environment", env),
    ))
    if err != nil {
        return nil, err
    }

    tp := sdktrace.NewTracerProvider(
		sdktrace.WithBatcher(exporter),
		sdktrace.WithResource(res), 
		sdktrace.WithSampler(sdktrace.AlwaysSample()),
	)
    
    // Set Global Provider
    otel.SetTracerProvider(tp)
    otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext{}, propagation.Baggage{}))
    
    return tp, nil
}